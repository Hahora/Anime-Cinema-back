import asyncio
import re
from typing import List, Dict, Any, Optional

from anime_parsers_ru import KodikParserAsync, ShikimoriParserAsync

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SINGLETON –ü–ê–†–°–ï–†–´
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

_kodik_parser: Optional[KodikParserAsync] = None
_shikimori_parser: Optional[ShikimoriParserAsync] = None
_parser_lock = asyncio.Lock()


async def get_kodik_parser() -> KodikParserAsync:
    """Singleton –¥–ª—è Kodik –ø–∞—Ä—Å–µ—Ä–∞"""
    global _kodik_parser
    async with _parser_lock:
        if _kodik_parser is None:
            _kodik_parser = KodikParserAsync(validate_token=False)
        return _kodik_parser


async def get_shikimori_parser() -> ShikimoriParserAsync:
    """Singleton –¥–ª—è Shikimori –ø–∞—Ä—Å–µ—Ä–∞"""
    global _shikimori_parser
    async with _parser_lock:
        if _shikimori_parser is None:
            _shikimori_parser = ShikimoriParserAsync()
        return _shikimori_parser


# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
async def get_parser() -> KodikParserAsync:
    return await get_kodik_parser()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def normalize_shikimori_id(raw_id: Any) -> Optional[str]:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç shikimori_id –∫ —Ñ–æ—Ä–º–∞—Ç—É Kodik (z123)"""
    if raw_id is None:
        return None
    sid = str(raw_id)
    if not sid.startswith("z"):
        sid = f"z{sid}"
    return sid


def get_clean_shikimori_id(raw_id: Any) -> Optional[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —á–∏—Å—Ç—ã–π shikimori_id –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ z (–¥–ª—è Shikimori API)"""
    if raw_id is None:
        return None
    sid = str(raw_id)
    if sid.startswith("z"):
        sid = sid[1:]
    return sid


def normalize_search_text(text: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞:
    - –£–±–∏—Ä–∞–µ—Ç [–¢–í-1], [–¢–í-2] –∏ —Ç.–¥.
    - –ó–∞–º–µ–Ω—è–µ—Ç —ë –Ω–∞ –µ
    - –£–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    """
    text = re.sub(r'\s*\[.*?\]\s*', ' ', text)
    text = text.replace('—ë', '–µ').replace('–Å', '–ï')
    text = re.sub(r'\s+', ' ', text).strip()
    return text


def create_search_variants(text: str) -> List[str]:
    """
    –°–æ–∑–¥–∞—ë—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞:
    - "–¥–∂–æ –¥–∂–æ" ‚Üí ["–¥–∂–æ –¥–∂–æ", "–¥–∂–æ–¥–∂–æ", "–¥–∂–æ-–¥–∂–æ"]
    - "–≤–∞–Ω –ø–∏—Å" ‚Üí ["–≤–∞–Ω –ø–∏—Å", "–≤–∞–Ω-–ø–∏—Å", "–≤–∞–Ω–ø–∏—Å"]
    - "–Ω–∞—Ä—É—Ç–æ" ‚Üí ["–Ω–∞—Ä—É—Ç–æ"]
    """
    text = normalize_search_text(text)
    variants = [text]

    words = text.split()

    if len(words) >= 2:
        # –í–∞—Ä–∏–∞–Ω—Ç —Å –¥–µ—Ñ–∏—Å–∞–º–∏: "–≤–∞–Ω –ø–∏—Å" ‚Üí "–≤–∞–Ω-–ø–∏—Å"
        hyphenated = "-".join(words)
        if hyphenated not in variants:
            variants.append(hyphenated)

        # –í–∞—Ä–∏–∞–Ω—Ç —Å–ª–∏—Ç–Ω–æ: "–¥–∂–æ –¥–∂–æ" ‚Üí "–¥–∂–æ–¥–∂–æ"
        joined = "".join(words)
        if joined not in variants:
            variants.append(joined)

        # –î–ª—è –¥–≤—É—Ö –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤: "–¥–∂–æ –¥–∂–æ" ‚Üí –æ—Å–æ–±—ã–π —Å–ª—É—á–∞–π
        if len(words) == 2 and words[0].lower() == words[1].lower():
            # "–¥–∂–æ –¥–∂–æ" ‚Üí "–¥–∂–æ–¥–∂–æ" (—É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤—ã—à–µ)
            pass

    return variants


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üñºÔ∏è –ü–û–õ–£–ß–ï–ù–ò–ï –ü–û–°–¢–ï–†–ê –ò–ó SHIKIMORI
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def get_poster_from_shikimori(shikimori_id: str) -> Optional[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å—Ç–µ—Ä –∞–Ω–∏–º–µ –∏–∑ Shikimori API
    
    Args:
        shikimori_id: ID –∞–Ω–∏–º–µ (—Å –∏–ª–∏ –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ 'z')
    
    Returns:
        URL –ø–æ—Å—Ç–µ—Ä–∞ –∏–ª–∏ None
    """
    clean_id = get_clean_shikimori_id(shikimori_id)
    if not clean_id:
        return None

    try:
        parser = await get_shikimori_parser()

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º deep_anime_info –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å—Ç–µ—Ä–∞
        info = await parser.deep_anime_info(
            shikimori_id=clean_id,
            return_parameters=['poster { originalUrl }']
        )

        if info and 'poster' in info:
            poster_data = info['poster']
            if isinstance(poster_data, dict):
                return poster_data.get('originalUrl')
            return poster_data

        return None

    except Exception as e:
        print(f"[SHIKIMORI POSTER ERROR] {e}")
        return None


async def get_posters_batch(shikimori_ids: List[str]) -> Dict[str, Optional[str]]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –ø–æ—Å—Ç–µ—Ä—ã –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞–Ω–∏–º–µ (–ø–∞–∫–µ—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å)
    
    Args:
        shikimori_ids: –°–ø–∏—Å–æ–∫ ID –∞–Ω–∏–º–µ
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å {shikimori_id: poster_url}
    """
    results = {}

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∏—Ç—å Shikimori
    semaphore = asyncio.Semaphore(5)

    async def fetch_poster(sid: str):
        async with semaphore:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            await asyncio.sleep(0.2)
            poster = await get_poster_from_shikimori(sid)
            results[sid] = poster

    tasks = [fetch_poster(sid) for sid in shikimori_ids if sid]
    await asyncio.gather(*tasks, return_exceptions=True)

    return results


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üîç –ü–û–ò–°–ö –ê–ù–ò–ú–ï
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def search_anime(title: str, limit: int = 12) -> List[Dict[str, Any]]:
    """
    –ü–æ–∏—Å–∫ –∞–Ω–∏–º–µ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ shikimori_id
    ‚úÖ –ü–æ—Å—Ç–µ—Ä—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ Shikimori
    ‚úÖ –£–º–Ω—ã–π –ø–æ–∏—Å–∫ —Å –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –∑–∞–ø—Ä–æ—Å–∞
    """
    parser = await get_kodik_parser()

    # –°–æ–∑–¥–∞—ë–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    search_variants = create_search_variants(title)
    normalized_title = normalize_search_text(title)
    print(f"üîç –ò—â–µ–º: '{title}' ‚Üí –≤–∞—Ä–∏–∞–Ω—Ç—ã: {search_variants}")

    grouped: Dict[str, Dict] = {}
    search_words = set(normalized_title.lower().split())

    # –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞—ë–º —Å–ª–∏—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    search_joined = normalized_title.lower().replace(" ", "").replace("-", "")

    try:
        # –ò—â–µ–º –ø–æ –≤—Å–µ–º –≤–∞—Ä–∏–∞–Ω—Ç–∞–º –∑–∞–ø—Ä–æ—Å–∞
        for variant in search_variants:
            if len(grouped) >= limit:
                break

            try:
                results = await parser.search(
                    title=variant,
                    limit=limit * 15,
                    only_anime=True,
                    include_material_data=True,
                    strict=False
                )

                print(f"üìä –í–∞—Ä–∏–∞–Ω—Ç '{variant}': Kodik –≤–µ—Ä–Ω—É–ª {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

                for item in results:
                    shiki_id = normalize_shikimori_id(item.get("shikimori_id"))
                    if not shiki_id:
                        continue

                    if shiki_id in grouped:
                        continue

                    material = item.get("material_data") or {}
                    title_ru = item.get("title", "")
                    title_orig = material.get("title_orig", "")

                    if not title_ru or len(title_ru) < 2:
                        continue

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                    normalized_anime_title = normalize_search_text(title_ru)
                    anime_words = set(normalized_anime_title.lower().split())

                    if title_orig:
                        normalized_orig_title = normalize_search_text(title_orig)
                        anime_words.update(normalized_orig_title.lower().split())

                    # –°–ª–∏—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                    anime_title_joined = normalized_anime_title.lower().replace(" ", "").replace("-", "")

                    matching_words = search_words.intersection(anime_words)
                    relevance_ratio = len(matching_words) / len(search_words) if search_words else 0

                    is_relevant = (
                            relevance_ratio >= 0.4 or
                            normalized_title.lower() in normalized_anime_title.lower() or
                            normalized_anime_title.lower() in normalized_title.lower() or
                            search_joined in anime_title_joined or
                            anime_title_joined in search_joined
                    )

                    if not is_relevant:
                        continue

                    grouped[shiki_id] = {
                        "id": shiki_id,
                        "title": title_ru,
                        "title_orig": title_orig,
                        "year": item.get("year"),
                        "type": item.get("type"),
                        "poster": None,
                        "screenshots": item.get("screenshots", []),
                        "description": material.get("description"),
                        "genres": material.get("genres", []),
                        "status": material.get("status"),
                        "rating": material.get("shikimori_rating"),
                        "_relevance": relevance_ratio
                    }

                    if len(grouped) >= limit:
                        break

            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ '{variant}': {e}")
                continue

        # ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç–µ—Ä—ã –∏–∑ Shikimori
        if grouped:
            print(f"üñºÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç–µ—Ä—ã –∏–∑ Shikimori –¥–ª—è {len(grouped)} –∞–Ω–∏–º–µ...")
            posters = await get_posters_batch(list(grouped.keys()))

            for shiki_id, poster_url in posters.items():
                if shiki_id in grouped:
                    grouped[shiki_id]["poster"] = poster_url
                    # Fallback –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç –µ—Å–ª–∏ –ø–æ—Å—Ç–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω
                    if not poster_url and grouped[shiki_id]["screenshots"]:
                        grouped[shiki_id]["poster"] = grouped[shiki_id]["screenshots"][0]

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        sorted_results = sorted(
            grouped.values(),
            key=lambda x: x.get("_relevance", 0),
            reverse=True
        )

        # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
        for r in sorted_results:
            r.pop("_relevance", None)
            r.pop("screenshots", None)

        print(f"‚úÖ –ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(sorted_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        return sorted_results[:limit]

    except Exception as e:
        print(f"[KODIK SEARCH ERROR] {e}")
        return []


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üìÑ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û–ë –ê–ù–ò–ú–ï
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def get_anime_details(shikimori_id: str) -> Optional[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω–∏–º–µ
    ‚úÖ –ü–æ—Å—Ç–µ—Ä –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ Shikimori
    """
    parser = await get_kodik_parser()
    shiki_id = normalize_shikimori_id(shikimori_id)

    if not shiki_id:
        return None

    try:
        # 1Ô∏è‚É£ –ü–µ—Ä–µ–≤–æ–¥—ã –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Ä–∏–π
        info = await parser.get_info(
            id=shiki_id,
            id_type="shikimori"
        )

        # 2Ô∏è‚É£ –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        search_result = await parser.search_by_id(
            id=shiki_id,
            id_type="shikimori",
            limit=1
        )

        if not search_result:
            return None

        anime = search_result[0]
        material = anime.get("material_data") or {}

        # 3Ô∏è‚É£ –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å—Ç–µ—Ä –∏–∑ Shikimori
        print(f"üñºÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç–µ—Ä –∏–∑ Shikimori –¥–ª—è {shiki_id}...")
        poster = await get_poster_from_shikimori(shiki_id)

        # Fallback –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç
        if not poster and anime.get("screenshots"):
            poster = anime["screenshots"][0]

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        translations = info.get("translations", [])
        seen_names = set()
        unique_translations = []

        for t in translations:
            name = t.get("name", "").strip()
            if name and name not in seen_names:
                seen_names.add(name)
                unique_translations.append(t)

        popular_studios = ["AniLibria", "AniDUB", "Animedia", "AniStar"]
        unique_translations.sort(
            key=lambda x: (
                popular_studios.index(x["name"]) if x["name"] in popular_studios else 999,
                -int(x.get("id", 0))
            )
        )

        return {
            "id": shiki_id,
            "title": anime.get("title"),
            "title_orig": material.get("title_orig"),
            "description": material.get("description"),
            "genres": material.get("genres", []),
            "type": anime.get("type"),
            "status": material.get("status"),
            "episodes_count": material.get("episodes_total"),
            "episodes_aired": material.get("episodes_aired"),
            "series_count": info.get("series_count", 1),
            "year": anime.get("year"),
            "rating": material.get("shikimori_rating"),
            "poster": poster,  # ‚úÖ –ü–æ—Å—Ç–µ—Ä –∏–∑ Shikimori
            "screenshots": anime.get("screenshots", []),
            "translations": unique_translations,
            "next_episode_at": material.get("next_episode_at"),
            "duration": material.get("duration")
        }

    except Exception as e:
        print(f"[KODIK DETAILS ERROR] {e}")
        return None


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üé¨ M3U8 –í–ò–î–ï–û
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def get_video_m3u8(
        shikimori_id: str,
        episode_num: int,
        translation_id: str,
        quality: int = 720
) -> Optional[str]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏ –Ω–∞ m3u8 –ø–ª–µ–π–ª–∏—Å—Ç
    """
    parser = await get_kodik_parser()
    shiki_id = normalize_shikimori_id(shikimori_id)

    if not shiki_id:
        return None

    try:
        seria_num = episode_num if episode_num > 0 else 0

        url = await parser.get_m3u8_playlist_link(
            id=shiki_id,
            id_type="shikimori",
            seria_num=seria_num,
            translation_id=str(translation_id),
            quality=quality
        )

        if url and url.startswith("//"):
            url = f"https:{url}"

        return url

    except Exception as e:
        print(f"[KODIK VIDEO ERROR] {e}")
        return None


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üé≠ –ê–ù–ò–ú–ï –ü–û –ñ–ê–ù–†–£
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def get_anime_by_genre(genre: str, page: int = 1, per_page: int = 10) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∏–º–µ –ø–æ –∂–∞–Ω—Ä—É —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
    ‚úÖ –ü–æ—Å—Ç–µ—Ä—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ Shikimori
    """
    parser = await get_kodik_parser()

    try:
        genre_lower = genre.lower()
        genre_mapping = {
            "—ç–∫—à–µ–Ω": ["action", "—ç–∫—à–µ–Ω", "—ç–∫—à–Ω", "–±–æ–µ–≤–∏–∫"],
            "–ø—Ä–∏–∫–ª—é—á–µ–Ω–∏—è": ["adventure", "–ø—Ä–∏–∫–ª—é—á–µ–Ω–∏—è"],
            "–∫–æ–º–µ–¥–∏—è": ["comedy", "–∫–æ–º–µ–¥–∏—è"],
            "–¥—Ä–∞–º–∞": ["drama", "–¥—Ä–∞–º–∞"],
            "—Ñ—ç–Ω—Ç–µ–∑–∏": ["fantasy", "—Ñ—ç–Ω—Ç–µ–∑–∏"],
            "—Ä–æ–º–∞–Ω—Ç–∏–∫–∞": ["romance", "—Ä–æ–º–∞–Ω—Ç–∏–∫–∞", "–º–µ–ª–æ–¥—Ä–∞–º–∞"],
            "sci-fi": ["sci-fi", "—Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞", "–Ω–∞—É—á–Ω–∞—è —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∞"],
            "—Ç—Ä–∏–ª–ª–µ—Ä": ["thriller", "—Ç—Ä–∏–ª–ª–µ—Ä"],
            "–º–∏—Å—Ç–∏–∫–∞": ["mystery", "–º–∏—Å—Ç–∏–∫–∞"],
            "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è": ["psychological", "–ø—Å–∏—Ö–æ–ª–æ–≥–∏—è"],
            "—à–∫–æ–ª–∞": ["school", "—à–∫–æ–ª–∞"],
            "—Å–ø–æ—Ä—Ç": ["sports", "—Å–ø–æ—Ä—Ç"],
            "—Å—ë–Ω—ç–Ω": ["shounen", "—Å—ë–Ω—ç–Ω", "shonen"],
            "—Å—ë–¥–∑—ë": ["shoujo", "—Å—ë–¥–∑—ë", "shojo"],
            "—Å—ç–π–Ω—ç–Ω": ["seinen", "—Å—ç–π–Ω—ç–Ω"],
            "–º–µ—Ö–∞": ["mecha", "–º–µ—Ö–∞"],
            "–º—É–∑—ã–∫–∞": ["music", "–º—É–∑—ã–∫–∞"],
            "–¥–µ—Ç–µ–∫—Ç–∏–≤": ["detective", "–¥–µ—Ç–µ–∫—Ç–∏–≤"],
            "—É–∂–∞—Å—ã": ["horror", "—É–∂–∞—Å—ã"],
            "–ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ—Å—Ç—å": ["slice of life", "–ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ—Å—Ç—å"],
            "–≤–æ–µ–Ω–Ω–æ–µ": ["military", "–≤–æ–µ–Ω–Ω–æ–µ"],
            "–∏—Å—Ç–æ—Ä–∏—è": ["historical", "–∏—Å—Ç–æ—Ä–∏—è"],
            "–±–µ–∑—É–º–∏–µ": ["dementia", "–±–µ–∑—É–º–∏–µ"],
            "–¥–µ–º–æ–Ω—ã": ["demons", "–¥–µ–º–æ–Ω—ã"],
            "–∏–≥—Ä—ã": ["game", "–∏–≥—Ä—ã"],
            "–º–∞–≥–∏—è": ["magic", "–º–∞–≥–∏—è"],
            "–ø–∞—Ä–æ–¥–∏—è": ["parody", "–ø–∞—Ä–æ–¥–∏—è"],
            "—Å–∞–º—É—Ä–∞–∏": ["samurai", "—Å–∞–º—É—Ä–∞–∏"],
            "—Å—É–ø–µ—Ä —Å–∏–ª–∞": ["super power", "—Å—É–ø–µ—Ä —Å–∏–ª–∞"],
            "–≤–∞–º–ø–∏—Ä—ã": ["vampire", "–≤–∞–º–ø–∏—Ä—ã"],
        }

        search_genres = genre_mapping.get(genre_lower, [genre_lower])

        pages_to_load = page * 3

        print(f"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º {pages_to_load} —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ Kodik (page={page})")

        data, next_page = await parser.get_list(
            limit_per_page=100,
            pages_to_parse=pages_to_load,
            include_material_data=True,
            only_anime=True
        )

        print(f"üìä –ü–æ–ª—É—á–µ–Ω–æ –∏–∑ Kodik: {len(data)} –∑–∞–ø–∏—Å–µ–π")

        grouped: Dict[str, Dict] = {}

        for item in data:
            shiki_id = normalize_shikimori_id(item.get("shikimori_id"))
            if not shiki_id or shiki_id in grouped:
                continue

            material = item.get("material_data") or {}
            item_genres = material.get("genres", [])

            genre_match = any(
                any(search.lower() in g.lower() for g in item_genres)
                for search in search_genres
            )

            if not genre_match:
                continue

            grouped[shiki_id] = {
                "id": shiki_id,
                "title": item.get("title"),
                "title_orig": material.get("title_orig"),
                "year": item.get("year"),
                "type": item.get("type"),
                "poster": None,  # ‚Üê –ó–∞–ø–æ–ª–Ω–∏–º –ø–æ–∑–∂–µ
                "screenshots": item.get("screenshots", []),
                "description": material.get("description"),
                "genres": item_genres,
                "status": material.get("status"),
                "rating": material.get("shikimori_rating")
            }

        all_results = list(grouped.values())

        # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
        offset = (page - 1) * per_page
        paginated = all_results[offset:offset + per_page]

        # ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç–µ—Ä—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if paginated:
            print(f"üñºÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç–µ—Ä—ã –∏–∑ Shikimori –¥–ª—è {len(paginated)} –∞–Ω–∏–º–µ...")
            poster_ids = [item["id"] for item in paginated]
            posters = await get_posters_batch(poster_ids)

            for item in paginated:
                poster_url = posters.get(item["id"])
                item["poster"] = poster_url
                # Fallback –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç
                if not poster_url and item.get("screenshots"):
                    item["poster"] = item["screenshots"][0]
                # –£–±–∏—Ä–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞
                item.pop("screenshots", None)

        has_more = len(all_results) > offset + per_page or next_page is not None

        print(f"‚úÖ –ñ–∞–Ω—Ä '{genre}': –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {len(all_results)}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º {len(paginated)}")

        return {
            "results": paginated,
            "has_more": has_more,
            "current_page": page
        }

    except Exception as e:
        print(f"[KODIK GENRE ERROR] {e}")
        return {"results": [], "has_more": False, "current_page": page}


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üî• –ü–û–ü–£–õ–Ø–†–ù–´–ï –ê–ù–ò–ú–ï
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def get_trending_anime(limit: int = 12) -> List[Dict[str, Any]]:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∞–Ω–∏–º–µ
    ‚úÖ –ü–æ—Å—Ç–µ—Ä—ã –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ Shikimori
    """
    parser = await get_kodik_parser()

    try:
        data, _ = await parser.get_list(
            limit_per_page=limit * 5,
            pages_to_parse=1,
            include_material_data=True,
            only_anime=True
        )

        grouped: Dict[str, Dict] = {}

        for item in data:
            shiki_id = normalize_shikimori_id(item.get("shikimori_id"))
            if not shiki_id or shiki_id in grouped:
                continue

            material = item.get("material_data") or {}

            grouped[shiki_id] = {
                "id": shiki_id,
                "title": item.get("title"),
                "year": item.get("year"),
                "type": item.get("type"),
                "poster": None,  # ‚Üê –ó–∞–ø–æ–ª–Ω–∏–º –ø–æ–∑–∂–µ
                "screenshots": item.get("screenshots", []),
                "rating": material.get("shikimori_rating"),
                "status": material.get("status")
            }

            if len(grouped) >= limit:
                break

        results = list(grouped.values())

        # ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç–µ—Ä—ã –∏–∑ Shikimori
        if results:
            print(f"üñºÔ∏è –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å—Ç–µ—Ä—ã –∏–∑ Shikimori –¥–ª—è {len(results)} –∞–Ω–∏–º–µ...")
            poster_ids = [item["id"] for item in results]
            posters = await get_posters_batch(poster_ids)

            for item in results:
                poster_url = posters.get(item["id"])
                item["poster"] = poster_url
                # Fallback –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç
                if not poster_url and item.get("screenshots"):
                    item["poster"] = item["screenshots"][0]
                # –£–±–∏—Ä–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –∏–∑ –æ—Ç–≤–µ—Ç–∞
                item.pop("screenshots", None)

        return results

    except Exception as e:
        print(f"[KODIK TRENDING ERROR] {e}")
        return []
